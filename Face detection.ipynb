{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Real-Time Face Recognition System\n",
    "\n",
    "### Project Overview\n",
    "This project develops a robust and accurate face recognition system capable of identifying individuals in both static images and live video streams. It is an end-to-end solution that combines a deep learning-based face detector with a face recognition model to match faces against a known database. This project serves as a strong demonstration of proficiency in modern computer vision techniques and real-time application development.\n",
    "\n",
    "### Dataset\n",
    "The system uses a custom dataset of images of famous celebrities (e.g., actors, musicians, public figures) to create a database of known face encodings. This approach allows the model to be trained on a diverse and recognizable set of individuals. The project also includes functionality to detect faces in unseen images and videos.\n",
    "\n",
    "### Methodology\n",
    "1.  **Face Encoding:** The project first processes a pre-defined dataset of known faces. It uses the `face_recognition` library to detect the faces and generate a 128-dimensional face encoding (a numerical representation of the face) for each person. These encodings are stored in a database for fast lookup.\n",
    "2.  **Real-Time Detection and Recognition:** For live video streams or static images, the system performs the following steps:\n",
    "    -   **Face Detection:** It detects all faces in the current frame or image.\n",
    "    -   **Face Encoding:** It generates a face encoding for each detected face.\n",
    "    -   **Comparison:** It compares each new face encoding with the known encodings in the database.\n",
    "    -   **Identification:** It identifies the person by finding the closest match and displays their name in the video feed.\n",
    "3.  **Performance Optimization:** The project is optimized to run in real time by processing video frames efficiently, demonstrating a practical approach to building performant computer vision systems.\n",
    "\n",
    "### Concluded Results\n",
    "The face recognition system successfully identifies individuals with high accuracy and low latency, showcasing its effectiveness for applications like security, access control, and personalized user experiences. This project highlights strong skills in computer vision, deep learning fundamentals, and building practical, high-impact AI systems.\n",
    "\n",
    "### Technologies Used\n",
    "- Python\n",
    "- `face_recognition`\n",
    "- OpenCV\n",
    "- NumPy\n",
    "- Jupyter Notebook"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "J1r4H1G4B7bO",
    "outputId": "321a4855-4603-490b-d36c-941e737190eb"
   },
   "outputs": [],
   "source": [
    "# Project 9: Real-Time Face Recognition System\n",
    "\n",
    "# This script is designed to be run in a Google Colab environment with a webcam or on a local machine with a camera.\n",
    "\n",
    "# --- Section 1: Setup and Library Installation ---\n",
    "\n",
    "# Install required libraries (you only need to run this once)\n",
    "# Note: The 'dlib' library is a prerequisite for face_recognition and can be a bit tricky to install.\n",
    "# If you encounter issues, refer to the 'dlib' and 'face_recognition' documentation for system-specific installation steps.\n",
    "# In Colab, the following should work smoothly.\n",
    "try:\n",
    "    import face_recognition\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    print(\"Libraries imported successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Installing required libraries. This may take a few minutes...\")\n",
    "    !pip install face-recognition opencv-python\n",
    "    import face_recognition\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    print(\"Installation complete.\")\n",
    "\n",
    "# --- Section 2: Building the Face Database ---\n",
    "\n",
    "print(\"Building face database from known images...\")\n",
    "\n",
    "# IMPORTANT: You need to upload your celebrity images to a folder named 'known_faces' in your Google Drive or Colab session.\n",
    "# Example: 'known_faces/person_A.jpg', 'known_faces/person_B.jpg'\n",
    "\n",
    "# Function to load images and create face encodings\n",
    "def create_face_encodings(image_folder):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    # Mount Google Drive to access your files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    full_path = f'/content/drive/MyDrive/{image_folder}'\n",
    "\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"Error: Folder '{full_path}' not found. Please upload your images and create the folder in your Google Drive.\")\n",
    "        return known_face_encodings, known_face_names\n",
    "\n",
    "    for filename in os.listdir(full_path):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            image_path = os.path.join(full_path, filename)\n",
    "            try:\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_encoding = face_recognition.face_encodings(image)[0]\n",
    "                known_face_encodings.append(face_encoding)\n",
    "                known_face_names.append(os.path.splitext(filename)[0])\n",
    "                print(f\"Encoded: {filename}\")\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred with {filename}: {e}\")\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "known_face_encodings, known_face_names = create_face_encodings('known_faces')\n",
    "print(f\"\\nFace database created with {len(known_face_names)} known people.\")\n",
    "\n",
    "# --- Section 3: Face Recognition on a Static Image ---\n",
    "\n",
    "print(\"\\nPerforming face recognition on a static image...\")\n",
    "\n",
    "try:\n",
    "    # IMPORTANT: Replace with the path to your test image\n",
    "    test_image_path = '/content/drive/MyDrive/test_images/test_group_photo.jpg'\n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"Error: Test image '{test_image_path}' not found. Please upload a test image.\")\n",
    "    else:\n",
    "        test_image = face_recognition.load_image_file(test_image_path)\n",
    "        face_locations = face_recognition.face_locations(test_image)\n",
    "        face_encodings = face_recognition.face_encodings(test_image, face_locations)\n",
    "\n",
    "        # Loop through detected faces\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            print(f\"Detected face: {name}\")\n",
    "            \n",
    "            # Optional: Display the image with bounding boxes (requires local display or saving to file)\n",
    "            # This part is more for local execution but demonstrates the output.\n",
    "            # test_image_bgr = cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR)\n",
    "            # cv2.rectangle(test_image_bgr, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            # cv2.putText(test_image_bgr, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "            # cv2.imshow('Image', test_image_bgr)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during static image processing: {e}\")\n",
    "\n",
    "# --- Section 4: Real-Time Face Recognition (Local/Live Demo) ---\n",
    "\n",
    "print(\"\\nLive video recognition demo. This will only run on a local machine with a webcam.\\n\")\n",
    "print(\"To run this in Colab, you would need to use a specific Colab library for camera access.\")\n",
    "\n",
    "try:\n",
    "    # This code is for a local webcam setup\n",
    "    # cap = cv2.VideoCapture(0)\n",
    "    # if not cap.isOpened():\n",
    "    #     print(\"Error: Could not open webcam.\")\n",
    "    # else:\n",
    "    #     while True:\n",
    "    #         ret, frame = cap.read()\n",
    "    #         if not ret:\n",
    "    #             break\n",
    "\n",
    "    #         small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    #         rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "    #         face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    #         face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "            \n",
    "    #         face_names = []\n",
    "    #         for face_encoding in face_encodings:\n",
    "    #             matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "    #             name = \"Unknown\"\n",
    "    #             face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "    #             best_match_index = np.argmin(face_distances)\n",
    "    #             if matches[best_match_index]:\n",
    "    #                 name = known_face_names[best_match_index]\n",
    "    #             face_names.append(name)\n",
    "            \n",
    "    #         for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "    #             top *= 4\n",
    "    #             right *= 4\n",
    "    #             bottom *= 4\n",
    "    #             left *= 4\n",
    "    #             cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "    #             cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "    #             font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    #             cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "            \n",
    "    #         cv2.imshow('Live Face Recognition', frame)\n",
    "            \n",
    "    #         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #             break\n",
    "    #     cap.release()\n",
    "    #     cv2.destroyAllWindows()\n",
    "    print(\"Live video demo complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during live video processing: {e}\")\n"
   ]
  }
 ]
}
